---
title: "Esboço do fluxo de trabalho de produção dos códigos"
date: "Criado em 31 de março de 2023, atualizado em `r format(Sys.time(), '%d de %B de %Y')`"
author: 
- Luciana Fusinatto
- Vitor Borges-Júnior
output: 
  html_notebook:
    toc: true
    number_section: true
    
---

```{r configuração, include=FALSE}
# carregar as funções da pasta R
# carregar função corrigir_diretorio
source(paste0(stringr::str_remove(getwd(), 'doc'), "R/corrigir_diretorio.R")) 

# carregar função grafico_expĺoratorio1
source(corrigir_diretorio(corrige = "R/grafico_exploratorio1.R")) 

# carregar dados da pasta doc
# carregar dados_filtrados.R da pasta data para o R
dados_filtrados <- readr::read_rds(corrigir_diretorio(corrige = "data/dados_filtrados.rds")) 
```

# ESBOÇO FLUXO DE TRABALHO DO PRODUTO 2 - CÓDIGOS

## *PARTE I – Cuidados antes de começar a rodar os códigos no R*

Pensar quais orientações são mais gerais e quais são importantes de acompanhar cada código.

### *Rstudio/Pacotes/versões/sistemas operacionais*

Sobre os pacotes, seria bom ter uma listinha de ‘library’ no início de cada código?
Talvez com uma breve explicação do que cada pacote faz, versão mínima... não sei.

### *Cuidados com a planilha .xlsx que será importada (para que mantenha o padrão da planilha de referência do ICMBio)* 

Imaginando que a planilha de dados do monitora é algo dinâmico, que o nome das colunas pode ser editado...

### *Como abrir os arquivos: como salvar e descompactar a pasta. Abrir projeto*

Um passo a passo de como salvar arquivo com os códigos e abrir.. Por exemplo, da forma como está é interessante descompactar a pasta e acessar os arquivos abrindo o projeto. Acho que isso pode mudar, dependendo de como viermos a entregar o produto final. Então podemos pensar nessa explicação no final.

### *Cuidados com diretório*

Se a gente ainda precisar ter algum tipo de preocupação quanto a isso. Acho que não.

### *Como rodar cada tipo de arquivo (markdown, shiny)*

Não é trivial para quem não está acostumado... usar runApp, knit... até mesmo o shift+enter para rodar as linhas de comando uma a uma

## *PARTE II – Carregando os dados para o R*

### *Dados brutos*

- todas espécies/UCs – carrega_dados_1.Rmd

### *Dados selecionados*

- por espécie/UC – carrega_dados_2.Rmd
até o momento usado com o exemplo da cutia na Resex Tapajós-Arapiuns

## *Parte III – Transformando dados para Distance*

### *Dados brutos*

- todas espécies/UCs – transforma_para_distanceR1.Rmd

### *Dados selecionados* 

- por espécie/UC – transforma_para_distanceR2.Rmd
até o momento usado com o exemplo da cutia na Resex Tapajós-Arapiuns

### *PARTE IV – Explorando os dados*

### *Selecionando os melhores modelos de estudo de acordo com os dados*

Critŕios:

- espécies com maior volume de dados total
- maior volume de dados por UC
 –  exploração_01.nb.html (acho que o .Rmd para gerar esse html não está na pasta Monitora). Eu tinha gostado bastante desse documento, com as tabelas dinâmicas. Talvez dê para selecionar as perguntas que são válidas de deixar/ tirar/ incluir.

WWF - Projeto Monitora

#### *Exploração de dados*

#### *Informações básicas*

#### *Quantas unidades de conservação ao todo?*

#### *Quantas observações por unidade de conservação ao todo?*

#### *Quantas observações foram validadas para quais níveis taxonômicos?*

#### *Quantas espécies ao todo?*

#### *Quantas observações para cada espécie?*

#### *Quais e quantas observações para cada espécie por unidades de conservação?*

#### *Quantas unidades de conservação foram amostradas em cada ano?*

#### *Quantas observações foram realizadas por UC em cada ano?*

#### Quantas observações para cada espécies por ano?

#### *Quantas observações para cada espécies por UC e por ano?*

#### *Quantas observações para cada espécies por UC, por estação e por ano?*

### *Selecionando melhores modelos de estudo considerando estratificação espacial/temporal – se há suficiência amostral (60-80 observações) por estrato*

### *Distribuição de distâncias*

```{r distribuicao_dsitancia, warning=FALSE}
# carregar dados_filtrados.R da pasta data para o R
dados_filtrados <- readr::read_rds(corrigir_diretorio(corrige = "data/dados_filtrados.rds")) 

# gerar o gráfico exploratório da distribuição de distâncias perpendiculares para a espécies Dasyrocta croconota na Resex Tapajós-Arapiuns
fig <- dados_filtrados |>
  # excluir NA's da variável distance
  tidyr::drop_na(distance) |> 
  grafico_exploratorio1()

fig
```


- Possíveis estratificações espaciais – EAs/UCs

					    - UCs/Espécies

	- Possíveis estratificações temporais – Espécie/UC/Ano 

### *Avaliando distância de truncamento *

- Gráficos de distribuição das frequências de ocorrência x distância perpendicular. Arquivos gráfico-exploratorio1.Rmd e gráfico-exploratorio2.Rmd (eu não sei como você fez para incluir aquela linha vermelha com o valor de w no gráfico exploratório 2, mas ficou legal)

### *avaliando covariáveis*

– As covariáveis devem ser pensadas de acordo com o grupo taxonômico. Espécies que formam grupos devem ter a covariável ‘size’. 

As estratégias de estratificação podem ser substituídas por covariáveis também (estratos espaciais/ ano)

Como covariável temporal, pode se pensar em usar, além do ano, a estação do ano (season), o horário do dia (para animais que variam a atividade). O horário do dia pode ser convertido em tempo após nascer do sol (como no exemplo). Mas para isso é necessário criar essa variável no dataset. E não é trivial porque precisa saber o horário de nascer do sol em cada dia/local para calcular.

### *gerar gráficos distância x covariável*

Exemplo de Gráficos de Marques et al. 2007

## *PARTE V – Ajustando os modelos*

Esse trabalho do Marque et al. 2007 é uma boa referência de como usar as abordagens CDS global, CDS estratificada e MCDS.

Aqui, é possível testar alguns caminhos de modelos. A estratificação só faz sentido quando o volume de dados for grande. Ainda assim o uso de covariáveis pode substituir a estratificação. Pensar em como orientar o uso dessas abordagens

### *Modelos pela abordagem CDS – dados globais*

- função ds do Distance (argumentos básicos: truncation; key, adjustment, scale... estudar argumentos para ver se mais algum interessa)

### *Modelos pela abordagem CDS – dados estratificados*

- Aqui precisa ver direitinho os cuidados que precisa ter para ajustar as funções nos dados estratificados. Acho que faz em blocos. Vai aplicando os mesmos parâmetros para todos os estratos a cada modelo.

- para cada estrato (espacial ou temporal) usar - função ds do Distance (argumentos básicos: truncation; key, adjustment, scale... estudar argumentos para ver se mais algum interessa)

### *Modelos pela abordagem MCDS – dados globais*

Aqui não faz sentido estratificar

- função ds do Distance (argumentos básicos: truncation; key, adjustment, scale... estudar argumentos para ver se mais algum interessa... para as covariáveis entra o argumento formula)

Dicas em Miller et al. 2019 sobre covariáveis (ver arquivo no driver).

## *PARTE VI – Avaliando os modelos*

### *Ajuste dos modelos *

- função gof_ds 

– para gerar Q-Q plots e testes associados

### *Selecionando modelos (AIC) *

– função summarize_ds_models

DICAS EXTRAS DE MILLER et al. 2019

## *PARTE VII – PRODUTO FINAL*

- Como organizar

- Interatividade

- gerar o tal documento automatizado contendo todo esse fluxo mais os resultados das análises;

- tentar transformar isso num dashboard/aplicativo único integrando cada etapa dessa numa das abas do dashboard

- Pacote targets seria últil?
