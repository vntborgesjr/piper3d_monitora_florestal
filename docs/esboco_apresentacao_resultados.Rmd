---
title: "Estrutura dos Resultados"
output: html_document
date: "2023-05-20"
---

# Fluxo de análise dos dados:

A seguir, apresentamos o fluxo de análise dos dados que envolve a fase exploratória, truncamento, ajuste e avaliação de modelos e estimativas de abundância e densidade para as espécies que selecionamos como modelo. Usamos como critérios de seleção tanto o número de ocorrências por Unidade de Conservação quanto a distribuição das frequências de observação, nos casos em que isso foi possível. De forma geral, as espécies com número satisfatório de ocorrências (\>60), apresentaram pico de observações próximos a zero.

Para todas as espécies modelo, nós implementamos duas estratégias para lidar com os efeitos indesejados nos dados: pico próximo a zero (*heaping near zero*) e número excessivo de repetições amostrais na mesma trilha. Para lidar com os picos, testamos o uso dos dados com distâncias exatas e distâncias agrupadas. Para lidar com as repetições, testamos a análise dos dados com todas as repetições e com o número de repetições reduzidas.

Especies com maior numero de ocorrencias/UC possibilitam testar, posteriormente, estratificações nos dados, preservando um número de ocorrências satisfatório dentro dos estratos. Por isso começamos apresentando um fluxo completo de análise, incluindo Amostragem por Distância Convencional, Amostragem por Distância com Múltiplas Covariáveis e Amostragem por Distância com Estratificação nos dados com as espécies com maior número de ocorrência.

## PRIMEIRO MODELO - Dasyprocta croconota - Resex Tapajós Arapiuns

![Fonte: biolib.cz](https://www.biolib.cz/IMG/GAL/BIG/205849.jpg)

Essa é a espécie com o mair número de ocorrências para uma mesma UC. Apresentou, como a maioria das espécies em diferentes UCs, um pico de ocorrências próximo a zero.

### Carregar Dados

Para selecionar do conjunto de dados da espécie e a Unidade de conservação de interesse, usar a função `transforma_para_distanceR_com_repeticao_filtra_uc_sp()`, especificando o nome da Unidade de conservação através do argumento `nome_uc` e o nome da espécie através do argumento `nome_sp`.

```{r}
# carregar dados
cutia_tap_arap <- transforma_para_distanceR_com_repeticao_filtra_uc_sp(
  nome_uc = "Resex Tapajos-Arapiuns",
  nome_sp = "Dasyprocta croconota"
) 

cutia_tap_arap
```

### Amostragem por Distância Convencional

#### Fluxo 1 - Distâncias exatas com todas as repetições

##### Plotando o histograma das frequências de ocorrência pela distância

O histograma interativo está disponível no app em Shiny `app_distancia_interativo.R`. A distribuição dos dados no histograma permite observar um pico de observações próximo a zero, além de uma considerável perda em detectabilidade a partir dos 20m. Vamos testar diferentes proporções de truncamento. É possível alterar a binagem dos histogramas através do argumento `largura_caixa`. Neste exemplo ajustamos para 1, o que facilita a observação de picos de detecação e efeitos de *heaping* nos dados.

```{r, fig.height=15, fig.width=10}
cutia_tap_arap |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 1)
```

##### Testando distância de truncamento (*w*)

Vamos explorar diferentes distâncias de truncamento para um mesmo modelo de distribuição half-normal. Optamos por truncar os dados pela percentagem para padronizar a rotina para diferentes espécies. Buckland et al. (2001) sugere um corte entre 5-10% das observações detectadas nas maiores distãncias. Vamos selecionar o valor de corte pelo modelo com melhor ajuste. Para os dados, testamos as seguintes proporções de corte de dados: 5, 10, 15, 20 e 25% das observações mais distantes. Geramos uma tabela comparando os modelos e também plotamos os gráficos dos modelos ajustados para os dados truncados.

###### Tabela com resumo comparativo dos modelos

```{r}
# conduz a selecao da melhor distancia de truncamento a partir do ajsute de modelos com funcao de deteccao half-normal sem termos de ajuste
cutia_tap_arap_dist_trunc <- cutia_tap_arap |> 
  selecionar_distancia_truncamento()

cutia_tap_arap_dist_trunc$selecao
```

###### Plotando o histograma com os dados truncados.

Histogramas resultantes dos modelos, com todas as distâncias de truncagem, para auxiliar na seleção da melhor distãncia.

```{r}
plotar_funcao_deteccao_selecao_distancia_truncamento(cutia_tap_arap_dist_trunc)
```

Após avaliar tanto o ajuste dos modelos quanto os gráficos, optamos por truncar 15% das observações feitas nas maiores distâncias. Apesar dos melhores valores de AIC e de ajuste do Cramér-von Mises para 25%, os histogramas com modelos ajustados para 25%, 20% e 15% apresentaram modelos quase lineares e com uma grande probabilidade de deteção nos últimos intervalos de distância. O modelo com corte de 10% apresentou uma curva decrescente e não tendeu a zero nas últimas distâncias. Já no modelos para 5% as funções de deteção tendem a zero nos últimos intervalos de distância. O corte de 10% das observações mais distantes resultou em uma distância de truncamento de 15m.

##### Ajustando diferentes modelos de funções de deteção

As funções de deteção são ajustadas através da função `ds()` no pacote Distence para o R. Para otimizar o fluxo de ajuste de funções, empacotamos as diferentes combinações de funções chave e termos de ajustes em três funções. São elas: `ajuste_modelos_distance_unif()`, para distribuição uniforme sem termos de ajuste e com termos de ajuste do tipo cosseno e polinomial simples, `ajuste_modelos_distance_hn()` para distribuição half-normal sem termos de ajuste e com termos de ajuste do tipo cosseno e polinomial de hermite; e `ajuste_modelos_distance_hr()` para distribuição hazard-rate sem termos de ajuste e com termos de ajuste do tipo cosseno e polinomial simples. Para definir a distância de truncamento dos dados é necessário fornecer o argumento `truncamento`, que pode ser definido tanto em percentagem de corte dos dados quanto em valor de distãncia.

###### Uniforme com termos de ajuste Cosseno e polinomial simples

```{r}
# ajustando a função de detecção uniforme para um truncamento de 10% dos dados
cutia_tap_arap_unif <- cutia_tap_arap |> 
  ajuste_modelos_distance_unif(truncamento = "10%")

```

Dentre as combinações de termos de ajustes para a função chave de distribuição uniforme, o Distance selecionou o modelo uniforme com ajuste polinomial simples, com as ordens 2, 4 e 6. Ele mantém esse modelo, e descarta os demais. Os *Warnings* indicando que a função de detecção não é estritamente monotônica avisam que os dados não foram constrangidos para a monotonicidade. Isso porque o uso de termos de ajustes, especialmente de ordens acima de 2, podem levar à perda da monotonidade (a curva pode se tornar crescente em algum momento, o que não é desejado). É preciso avaliar se a fala desse constragimento levou efetivamente à perda da monotonicidade ao olhar os gráficos de ajuste dos modelos.

###### Half-Normal sem termos de ajuste e com termos de ajuste Cosseno e Polinomial de Hermite

```{r}
# ajustando a função de detecção half-normal para um truncamento de 10% dos dados
cutia_tap_arap_hn <- cutia_tap_arap |> 
  ajuste_modelos_distance_hn(truncamento = "10%")
```

Neste caso, o modelo selecionado pelo Distance foi o Half-normal sem nenhum termo de ajuste.

###### Hazard-rate sem termos de ajuste e com termos de ajuste Cosseno e Polinomial de Hermite

```{r}
# ajustando a função de detecção hazard-rate para um truncamento de 10% dos dados
cutia_tap_arap_hr <- cutia_tap_arap |> 
  ajuste_modelos_distance_hr(truncamento = "10%")
```

Aqui o melhor modelo selecionado pelo Distance foi o Hazard-rate sem os termos de ajuste. Nesse caso, também há um *warning* para o problema na distribuição dos dados, que apresentam um pico próximo a distância zero e não são bem ajustados pelo hazard-hate.

##### Comparando os modelos

Para comparar os modelos é preciso avaliar três critérios: AIC, ajuste e forma das funções nos gráficos e bondade de ajuste. O pacote distance possui a função `summarize_ds_models`que gera uma tabela com os modelos para comparação de alguns parâmetros: a primeira coluna **Model**, indica as funções chaves e respectivos termos de ajuste; a coluna **Formula** apresenta as covariáveis, quando incluídas no modelo, ou \~1, quando não há covariáveis; **C-vM p-value** vai apresentar os valores de p para o teste de bondade de ajuste de Cramér-von Mises; $\hat{P_a}$ apresenta a probalidade de deteção global estimada para cada modelo; **se(**$\hat{P_a}$) apresenta o erro padrão para as estimativas de probabilidade de detecção; e $\Delta$AIC apresenta os valores de delta AIC.

###### Tabela com o resumo comparativo dos modelos

```{r}
lista_modelos_ajustados <- list(
  `half-normal` = cutia_tap_arap_hn, 
  `hazard-rate` = cutia_tap_arap_hr, 
  `uniforme` = cutia_tap_arap_unif
)

selecao_funcao_deteccao_termo_ajsute <- selecionar_funcao_deteccao_termo_ajuste(lista_modelos_ajustados)

selecao_funcao_deteccao_termo_ajsute
```

Dentre os modelos testados, o que apresentou melhor valor de ajuste e AIC foi o hazard-rate. O ajuste do Cramér-von Mises foi consideravelmente maior que os demais (para esse tipo de teste, quanto maior o valor de p, melhor o ajuste), assim como as diferenças no delta AIC foram bastante elevadas.

###### Gráficos de ajuste das funções de deteção às probabilidades de deteção

```{r}
modelos_selecionados <- list(
  cutia_tap_arap_hr$`Sem termo`,
  cutia_tap_arap_unif$`Cosseno`,
  cutia_tap_arap_hn$`Cosseno`,
  cutia_tap_arap_unif$`Polinomial simples`,
  cutia_tap_arap_hn$`Sem termo`
)

plotar_funcao_deteccao_modelos_selecionados(modelos_selecionados)
```

Olhando para os histogramas com modelos ajustados, é possível observar o efeito do acúmulo de observações próximo a zero. O modelo com a função chave hazard-hate sem termos de ajuste, apesar de ter apresentado o melhor valor de ajuste pelo Cramér-von Mises e o melhor valor de AIC, apresentou dois problemas. As probalidades de deteção estimadas por intevalo de distância (barras cinzas), ficaram muito baixas. Além disso, a curva da função de deteção apresenta pico na distância próxima a zero, decaindo rapidamente e se aproximando de zero ao longo do eixo das distãncias. Todos os outros quatro modelos tiveram ajuste e AIC bastante inferiores ao hazard-hate. Entretanto as curvas estão relativamente melhores. As curvas do segundo e terceiro modelo, uniforme com ajuste cosseno e half-normal com ajuste cosseno, respectivamente, tendem à perda de monotonicidade. As duas últimas curvas, para os modelos uniforme com ajuste polinomial simples e half-normal sem ajuste, não perdem a monotonicidade. De forma geral, as probabilidades de detecção não têm um bom ajuste abaixo da curva, e não apresentam um decaimento gradual com a distância. Esses são problemas inerentes à distribuição dos dados.

###### Teste de bondade de ajuste dos modelos e Q-Q plots

##### Avaliando as estimativas de Abundância e Densidade

#### Fluxo 2 - Distâncias exatas com repetições reduzidas

##### Filtrando os dados para reduzir as repetições

```{r}
dados_selecionados <- carregar_dados_selecionados()
cutia_tap_arap_quase_sem_repeticao <- transforma_para_dsitanceR_quase_sem_repeticao_filtra_uc_sp(
  dados = dados_selecionados,
  nome_uc = "Resex Tapajos-Arapiuns",
  nome_sp = "Dasyprocta croconota"
)

cutia_tap_arap_quase_sem_repeticao
```


##### Plotando o histograma das frequências de ocorrência pela distância

```{r, fig.height=15, fig.width=10}
cutia_tap_arap_quase_sem_repeticao |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 1)
```

##### Testando distância de truncamento (*w*)

###### Tabela com resumo comparativo dos modelos

```{r}
# conduz a selecao da melhor distancia de truncamento a partir do ajsute de modelos com funcao de deteccao half-normal sem termos de ajuste
cutia_tap_arap_quase_sem_repeticao_dist_trunc <- cutia_tap_arap_quase_sem_repeticao |> 
  selecionar_distancia_truncamento()

cutia_tap_arap_quase_sem_repeticao_dist_trunc$selecao
```


###### Plotando o histograma com os dados truncados.

```{r}
plotar_funcao_deteccao_selecao_distancia_truncamento(cutia_tap_arap_quase_sem_repeticao_dist_trunc)

```

##### Ajustando diferentes modelos de funções de deteção

###### Uniforme + Cosseno

###### Half-Normal sem termos de ajuste e com termos de ajuste

###### Hazard-rate sem termos de ajuste e com termos de ajuste

##### Comparando os modelos

###### Tabela com o resumo comparativo dos modelos

###### Gráficos de ajuste das funções de deteção às probabilidades de deteção

###### Teste de bondade de ajuste dos modelos e Q-Q plots

##### Avaliando as estimativas de Abundância e Densidade

#### Fluxo 3 - Distâncias agrupadas com todas as repetições

Aqui vamos partir do mesmo conjunto de dados do Fluxo 1 (`cutia_tap_arap`), com todas as repetições, mas vamos agrupar as distâncias em intervalos. Vamos usar o mesmo valor de truncamento, removendo 10% das observações nas maiores distâncias, o que significa que aproveitaremos as observações feitas até 15m de distância do observador.

##### Plotando o histograma das frequências de ocorrência pela distância

O histograma interativo está disponível no app em Shiny `app_distancia_interativo.R`.

Aqui, plotamos quatro histogramas com binagens diferentes, para observar o efeito de agrupar os dados sobre as distribuições das frequências de ocorrência nos histogramas.

```{r, fig.height=15, fig.width=10}
cutia_tap_arap |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 1)

cutia_tap_arap |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 2)

cutia_tap_arap |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 3)

cutia_tap_arap |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 5)

```

##### Definindo os intevalos de distância de agrupamento
```{r}
cutia_tap_arap_bin1 <- create_bins(
  cutia_tap_arap[!is.na(cutia_tap_arap$distance),], 
  c(1, 3.8, 6.6, 9.4, 12.2, 15,50)
)
```
###### Ajustando diferentes modelos de funções de detecção

```{r}

cutia_tap_arap_bin1_unif <- cutia_tap_arap_bin1 |> 
  ajuste_modelos_distance_unif(truncamento = 15)

```

###### Tabela com resumo comparativo dos modelos

###### Plotando o histograma com os dados truncados.

##### Ajustando diferentes modelos de funções de deteção

###### Uniforme + Cosseno

###### Half-Normal sem termos de ajuste e com termos de ajuste

###### Hazard-rate sem termos de ajuste e com termos de ajuste

##### Comparando os modelos

###### Tabela com o resumo comparativo dos modelos

###### Gráficos de ajuste das funções de deteção às probabilidades de deteção

###### Teste de bondade de ajuste dos modelos e Q-Q plots

##### Avaliando as estimativas de Abundância e Densidade

#### Fluxo 4 - Distâncias agrupadas com repetições reduzidas

##### Plotando o histograma das frequências de ocorrência pela distância

O histograma interativo está disponível no app em Shiny `app_distancia_interativo.R`. A distribuição dos dados no histograma permite observar um pico de observações próximo a zero, além de uma considerável perda em detectabilidade a partir dos 20m. Vamos testar diferentes proporções de truncamento.

##### Testando distância de truncamento (*w*)

Vamos explorar diferentes distâncias de truncamento para um mesmo modelo de distribuição half-normal. Optamos por truncar os dados pela percentagem para padronizar a rotina para diferentes espécies. Buckland et al. (2001) sugere um corte entre 5-10% das observações detectadas nas maiores distãncias. Vamos selecionar o valor de corte pelo modelo com melhor ajuste.

###### Tabela com resumo comparativo dos modelos

###### Plotando o histograma com os dados truncados.

##### Ajustando diferentes modelos de funções de deteção

###### Uniforme + Cosseno

###### Half-Normal sem termos de ajuste e com termos de ajuste

###### Hazard-rate sem termos de ajuste e com termos de ajuste

##### Comparando os modelos

###### Tabela com o resumo comparativo dos modelos

###### Gráficos de ajuste das funções de deteção às probabilidades de deteção

###### Teste de bondade de ajuste dos modelos e Q-Q plots

##### Avaliando as estimativas de Abundância e Densidade

### Amostragem por Distância com Múltiplas Covariáveis

Após testar as quatro estratégias anteriores para lidar com efeitos indesejados nos dados, escolhemos a estratégia com melhores resultados, considerando a bondade de ajuste dos modelos e os coeficientes de variação das estimativas de abundância e densidade, para adicionar covariávies. Consideramos, com base nos dados do Programa Monitora, duas covariáveis. A primeira dela, tamanho do grupo. De forma geral, pode existir uma tendência a um viés no tamanho do grupo com a distância, com a perda de detectabilidade para grupos menores. Além disso, o tamanho do grupo também é utilizado para corrigir as estimativas de abudância e densidade. A outra covariável criamos a partir dos dados de horário de início e horário de registro das espécies, calculando os minutos após o início da amostragem. Muitas espécies variam sua atividade ao longo do dia, e podem ser mais ou menos detectáveis de acordo com o horário.

#### Explorando covariáveis

##### Gráficos exploratórios

###### Distância x Tamanho do grupo

###### Distância x Minutos após o início da amostragem

##### Ajustando diferentes modelos com covariáveis

Para o uso de coveriáveis, podemos usar somente as distribuições half-normal ou hazard-rate, pois ambas possuem o parâmetro escalar pelo qual o vetor das covariáveis será multiplicado. Não é recomendável o uso de termos de ajuste com o uso de covariáveis pela grande chance de perda de monotonicidade nas curvas das funções de detecção. Assim, vamos trabalhar com as seguintes combinações de modelos

###### Half-normal sem termos de ajuste (HN)

###### HN + Tamanho do grupo (HN + S)

###### HN + Minutos após o início da amostragem (HN + M)

###### HN + Tamanho do grupo + Minutos após início da amostragem (HN + S + M)

###### Hazard-rate sem termos de ajuste (HZ)

###### HZ + Tamanho do grupo (HZ + S)

###### HZ + Minutos após o início da amostragem (HZ + M)

###### HZ + Tamanho do grupo + Minutos após início da amostragem (HZ + S + M)

##### Comparando os modelos

###### Tabela com o resumo comparativo dos modelos

###### Gráficos de ajuste das funções de deteção às probabilidades de deteção

###### Teste de bondade de ajuste dos modelos e Q-Q plots

##### Avaliando as estimativas de Abundância e Densidade

Para o uso de covariáveis, as estimativas de abundância/densidade devem ser feitas através do bootstrap.

### Amostragem por Distância com Estratificação

O uso da estratificação, no caso dos dados do progama monitora, pode ser usado a partir de duas abordagens. A primeira delas seria focada na dinâmica populacional, para estimar abundâncias e densidades em períodos amostrais diferentes e acompanhar o tamanho da população ao longo do tempo. Para essa abordagem, estratificar os dados por ano permite que sejam feitas estas estimativas. O pacote Distance para o R é mais limitado que o programa Distance para o Windows em termos de opções de comando para estratificar os dados por amostragem, e entende a estratificação através da variável `Region.Label`, usada para informar estratificação espacial. Como a nossa intenção é estratificar por ano, vamos inserir os anos como estratos na variável `Region.Label`, assumindo que se tratam de amostras diferentes, pois nosso interesse está na variação nos dados, independente da fonte de variação ser espacial ou temporal.

Uma outra abordagem possível é usar a estratificação espacial. No caso dos dados do Programa Monitora, a variação entre as UCs para uma mesma espécie parece ser mais relevante que a variação dentro de uma mesma UC, pois entendemos que não há um desenho amostral sistematizado para a distriubuição das Estações Amostrais em cada UC que justifique testar hipóteses sobre variação nas abundâncias e densidades. Assim, optamos por usar a estratificação espacial para dados de uma mesma espécie em diferentes UCs. Exploramos em maiores detalhes as duas abordagens a seguir.

#### Estraficação dos dados por Ano de amostragem:

##### Explorando os dados dentro de cada estrato temporal:

Antes de ajustar os modelos e gerar as estimativas, é importante verificar o número de ocorrências dentro de cada ano. Pois, ao estratificar, ajustaremos uma função de detecção para cada estrato.

###### Tabela com número de ocorrências por ano para Dasyprocta croconota na Resex Tapajós-Arapiuns

Tabela com dados filtrados. Tabela dinâmica disponível na **Parte XXX**

##### Ajustando a função de detecção para os dados estratificados

Até agora, exploramos diferentes abordagens para a Amostragem por Distância convencional e com o uso de Múltiplas Covariávies, e selecionamos o modelo que melhor se ajustou aos dados. Nesta etapa, não vamos testar novos modelos de ajuste. Iremos ajustar o melhor modelo do fluxo anterior aos dados estratificados.

###### Tabela com o resumo dos resultados de ajuste do modelo para cada ano

##### Avaliando as estimativas de Abundância e Densidade

Para o uso de covariáveis, as estimativas de abundância/densidade devem ser feitas através do bootstrap.

#### Estratificação dos dados por Unidade de Conservação

Aqui, vamos explorar para uma mesma espécie, dados de diferentes Unidades de Conservação ao mesmo tempo.

##### Explorando os dados dentro de cada estrato espacial:

Antes de ajustar os modelos e gerar as estimativas, é importante verificar o número de ocorrências dentro de cada UC. Pois, ao estratificar, ajustaremos uma função de detecção para cada estrato. Caso tenham UCs com um número muito baixo de ocorrências (\<30), considerar não incluir na análise.

###### Tabela com número de ocorrências por Unidade de Conservaçaõ para Dasyprocta croconota

Tabela com dados filtrados. Tabela dinâmica disponível na **Parte XXX**

##### Plotando o histograma das frequências de ocorrência pela distância

O histograma interativo está disponível no app em Shiny `app_distancia_interativo.R`. A distribuição dos dados no histograma permite observar um pico de observações próximo a zero, além de uma considerável perda em detectabilidade a partir dos 20m. Vamos testar diferentes proporções de truncamento.

##### Testando distância de truncamento (*w*)

Vamos explorar diferentes distâncias de truncamento para um mesmo modelo de distribuição half-normal. Optamos por truncar os dados pela percentagem para padronizar a rotina para diferentes espécies. Buckland et al. (2001) sugere um corte entre 5-10% das observações detectadas nas maiores distãncias. Vamos selecionar o valor de corte pelo modelo com melhor ajuste.

###### Tabela com resumo comparativo dos modelos

###### Plotando o histograma com os dados truncados.

##### Ajustando diferentes modelos para dados Globais

\#**AQUI A GENTE PRECISA TOMAR UMA DECISÃO IMPORTANTE**

É necessário testar os quatro fluxos: todas/poucas repetições x distancias exatas/agrupadas? Preciso ver os resultados dos fluxos anteriores para planejar melhor esta etapa.

Para a estratificação, vamos testar diretamento os modelos com e sem covariáveis. Vamos nos limitar às distribuições half-normal e hazard-rate, pois são as únicas que comportam o uso das covariáveis.

###### Half-normal sem termos de ajuste (HN)

###### HN + Tamanho do grupo (HN + S)

###### HN + Minutos após o início da amostragem (HN + M)

###### HN + Tamanho do grupo + Minutos após início da amostragem (HN + S + M)

###### Hazard-rate sem termos de ajuste (HZ)

###### HZ + Tamanho do grupo (HZ + S)

###### HZ + Minutos após o início da amostragem (HZ + M)

###### HZ + Tamanho do grupo + Minutos após início da amostragem (HZ + S + M)

##### Comparando os modelos

###### Tabela com o resumo comparativo dos modelos

###### Gráficos de ajuste das funções de deteção às probabilidades de deteção

###### Teste de bondade de ajuste dos modelos e Q-Q plots

##### Avaliando as estimativas de Abundância e Densidade

Para modelos com covariáveis as estimativas de abundância e densidade devem ser feitas por bootstrap

##### Ajustando diferentes modelos para os dados Estratificados

A redução no tamanho amostral geralmente faz com que os modelos para os dados globais tenham um ajuste melhor que os modelos ajustados aos estratos. Um critério para avaliar este ajuste é comparar o somatório dos valores de AIC para cada estrato com o valor de AIC do modelo global. Se a soma dos valores de AIC dos estratos for menor que o AIC global, significa que o ajuste foi melhor para os dados estratificados.

\#**AQUI TAMBÉM PRECISA TOMAR UMA DECISÃO IMPORTANTE**

Rodamos todos os modelos para os dados estratificados? Ou partimos do melhor modelo para dados globais?

###### Half-normal sem termos de ajuste (HN)

###### HN + Tamanho do grupo (HN + S)

###### HN + Minutos após o início da amostragem (HN + M)

###### HN + Tamanho do grupo + Minutos após início da amostragem (HN + S + M)

###### Hazard-rate sem termos de ajuste (HZ)

###### HZ + Tamanho do grupo (HZ + S)

###### HZ + Minutos após o início da amostragem (HZ + M)

###### HZ + Tamanho do grupo + Minutos após início da amostragem (HZ + S + M)

##### Comparando os modelos

###### Tabela com o resumo comparativo dos modelos

Olhar também valores brutos de AIC dos modelos globais e comparar com os estratificados.

###### Gráficos de ajuste das funções de deteção às probabilidades de deteção

###### Teste de bondade de ajuste dos modelos e Q-Q plots

##### Avaliando as estimativas de Abundância e Densidade

Para modelos com covariáveis as estimativas de abundância e densidade devem ser feitas por bootstrap
