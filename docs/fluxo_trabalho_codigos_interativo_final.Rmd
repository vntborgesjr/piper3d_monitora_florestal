---
title: "Fluxo de trabalho: de producao dos codigos dos dados de Amostragem por Distancia
  - Programa Monitora ICMBio/MMA"
author: "Luciana Fusinatto \n Vitor Borges-Júnior"
date: Criado em 31 de março de 2023, atualizado em `r format(Sys.time(), '%d de %B
  de %Y')`
output:
  html_notebook:
    toc: yes
    toc_depth: 5
    toc_float: no
    number_section: yes
    code_folding: show
editor_options:
  markdown:
    wrap: 72
---

# **PARTE I -- Cuidados antes de começar a rodar os códigos no R**

Para que o arquivo `fluxo_de_trabalho_codigos_interativo_final.Rmd` funcione de maneira adequada em sua máquina, você deve descompactar o arquivo `piper3D_monitora_florestal.zip`. Uma nova pasta com o mesmo nome será criada no diretório escolhido para executar a descompactação. Nela, você deverá clicar duas vezes sobre o ícone `Monitora.Rproj` para começar a executar os arquivos contidos no projeto. Ao realizar esse procedimento, você garantirá que seu diretório de trabalho esteja configurado como o diretório da pasta `piper3d_monitora_florestal` assegurando o funcionamento correto dos códigos contidos no projeto.

## Carregando as funções

```{r configuração, include=FALSE, warning=FALSE, message=FALSE}
library(Distance)
library(dplyr)
library(DT)
library(forcats)
library(ggpubr)
library(ggplot2)
library(here)
library(lubridate)
library(mrds)
library(plotly)
library(purrr)
library(readr)
library(readxl)
library(stringi)
library(stringr)
library(tidyr)
library(tidyselect)
source(paste0(here::here(), "/R/minhas_funcoes.R"))

```

## **Rstudio/Pacotes/versões/sistemas operacionais**

A tabela aseguir é uma referência para as versões dos pacotes utilizados no nesse projeto. Para garantir a reprodução dos códigos, é importante que o R e os pacotes usados no projeto apresentem as configurações mínimas contidas na tabela 1.

```{r}
# gerar informações sobre os pacotes carregados
info <- sessionInfo()

# gerar tabela com os pacotes e versões
tribble(
  ~Pacotes,                         ~Versão,
  version$language,                 version$version.string,
  info$otherPkgs$dplyr$Package,     info$otherPkgs$dplyr$Version,
  info$otherPkgs$Distance$Package,  info$otherPkgs$Distance$Version,
  info$otherPkgs$DT$Package,        info$otherPkgs$DT$Version,
  info$otherPkgs$forcats$Package,        info$otherPkgs$forcats$Version,
  info$otherPkgs$flextable$Package, info$otherPkgs$flextable$Version,
  info$otherPkgs$ggplot2$Package,     info$otherPkgs$ggplot2$Version,
  info$otherPkgs$ggpubr$Package,     info$otherPkgs$ggpubr$Version,
  info$otherPkgs$here$Package,     info$otherPkgs$here$Version,
  info$otherPkgs$lubridate$Package, info$otherPkgs$lubridate$Version,
  info$otherPkgs$mrds$Package,     info$otherPkgs$mrds$Version,
  info$otherPkgs$plotly$Package,    info$otherPkgs$plotly$Version,
  info$otherPkgs$purrr$Package,     info$otherPkgs$purrr$Version,
  info$otherPkgs$readr$Package,     info$otherPkgs$readr$Version,
  info$otherPkgs$readxl$Package,     info$otherPkgs$readxl$Version,
  info$otherPkgs$stringi$Package,     info$otherPkgs$stringi$Version,
  info$otherPkgs$stringr$Package,     info$otherPkgs$stringr$Version,
  info$otherPkgs$tibble$Package,    info$otherPkgs$tibble$Version,
  info$otherPkgs$tidyr$Package,     info$otherPkgs$tidyr$Version,
  info$otherPkgs$tidyselect$Package,info$otherPkgs$tidyselect$Version
) |> 
  flextable::qflextable() |> 
  flextable::set_caption(
    "Tabela 1 - configuração de pacotes necessários e respectivas versões mínimas que devem ser utilizadas para reproduzir os códigos"
  )
```

## **Cuidados com a planilha .xlsx que será importada (para que mantenha o padrão da planilha de referência do ICMBio)**

A primeira função utlizada, `carregar_dados_brutos_xlsx()`, irá
carregar a planilha em formato excel,
`Planilha Oficial consolidada de Masto-aves 2014-21 Validada CEMAVE CPB CENAP.xlsx`,
e gera automaticamente o arquivo `dados_brutos.rds` na pasta
`data-raw`. A função seguinte a ser utilizada, `carregar_dados_completos()` que irá carregar o arquivo
`dados_brutos.rds`. Essa função foi escrita para carrega os dados e
operar uma série de transformações para devolvê-lo no formato
padronizado do programa **DISTANCE** para Windows. Portanto, para
garantir a reprodutibilidade dos códigos produzidos em versões
atualizadas da base de dados do Monitora, é importante tomar alguns
cuidados.

O primeiro e mais importante cuidado é **manter a consistência dos nomes das colunas** em versões atualizadas da base de dados do Monitora. Além de carregar os dados, a função `carregar_dados_completos()` aplica uma série de transformações nas colunas. Seus nomes são alterados, e a essas são atribuídos tipos apropriados (data, caracter, fator, inteiro e numérico), linhas são eliminadas e novas colunas são gereadas. Para
exemplificar, veja o código abaixo. Ele foi escrito para executar as
primeiras transformações nos dados e constitui o corpo da função
`carregar_dados_filtrados()`.

```{r}
# carregar a base de dados do Monitora
dados_brutos <- carregar_dados_brutos_xlsx()

# gerar o data.frame desejado reproduzindo as transformações realizadas pela função carregar_dados_completos()
dados_filtrados <- dados_brutos |>  
  # selecionar as colunas necessárias para as analises, padronizando os nomes para o formato DISTANCE
  dplyr::select(
    uc_code = CDUC,
    uc_name = `Local - Nome da Unidade de Conservacao`,
    ea_number = `Numero da Estacao Amostral`,
    ea_name = `Nome da EA`,
    season = `Estacao do ano`,
    sampling_day = `data da amostragem`,
    day_effort = `Esforco de amostragem tamanho da trilha (m)`,
    sp = `Especies validadas para analise do ICMBio`,
    distance = `distancia (m)     do animal em relacao a trilha`,
    group_size = `n de animais`,
    observadores = `nome dos observadores`
  ) |>
  # atribuir os tipos corretos às colunas e criar novas colunas
    dplyr::mutate(
      uc_category = stringi::stri_extract_first_words(
      uc_name
    ),
    # abrevia o nome das UCs
    uc_name_abv = forcats::lvls_revalue(
      uc_name,
      new_levels = c(
        "ETM", "EM", "EN", "ESGT", "FJ", "PCV", "PA", "PSBoc", "PSBod", "PSC",
        "PSM", "PSC", "PSD", "PSP", "PSO", "PPN", "PCO", "PI", "PJaú", "PJur",
        "PMR", "PS", "PV", "PCA", "PMT", "RG", "RJ", "RTap", "RU", "RG",
        "RTrom", "RAT", "RBA", "RCI", "RCM", "RRC", "RROP", "RIA", "RRA", "RTA"
      )
    ),
      # atribuir o tipo data à coluna sampling_day
      year = lubridate::year(
        sampling_day
      ),
      # atribuir o tipo fator às colunas do tipo caracter
      across(
        where(
          is.character
        ),
        as.factor
      ),
      # substituir separadores de nome por ","
      novo = stringr::str_replace_all(
        observadores, 
        " e ",
        ", "
      ),
      # substituir separadores de nome por ","
      novo = stringr::str_replace_all(
        novo, 
        " E ",
        ", "
      ),
      # substituir separadores de nome por ","
      novo = stringr::str_replace_all(
        novo, 
        "/",
        ", "
      ),
      # substituir separadores de nome por ","
      novo = stringr::str_replace_all(
        novo, 
        ";",
        ", "
      ),
      # substituir separadores de nome por ","
      novo = stringr::str_replace_all(
        novo, 
        " a ",
        ", "
      ) 
    ) |>
  # transformar os nomes dos observadores da coluna novo em colunas individuais
tidyr::separate_wider_delim(
  novo, 
  ",",
  names = c(
    "obs1", "obs2", "obs3", "obs4", "obs5", "obs6"
  ),
  too_few = "align_start"
) |> 
  # gerar uma nova coluna number_observers com o número total de observadores em um mesmo transecto
  dplyr::mutate(
    # se o valor da observação é diferente de NA, substituir por 1, se for NA, substituir por 0
    obs1 = ifelse(!is.na(obs1), 1, 0),
    obs2 = ifelse(!is.na(obs2), 1, 0),
    obs3 = ifelse(!is.na(obs3), 1, 0),
    obs4 = ifelse(!is.na(obs4), 1, 0),
    obs5 = ifelse(!is.na(obs5), 1, 0),
    obs6 = ifelse(!is.na(obs6), 1, 0),
    # gera nova coluna number_observers a partir da soma das colunas de observadores individuais
    number_observers = obs1 + obs2 + obs3 + obs4 + obs5 + obs6
  ) |> 
  # agrupar os dados pelas colunas ea_name e sampling_day
  group_by(
    ea_name, 
    sampling_day
  ) |> 
  # aninhar as observações agrupadas uem listas
  nest() |> 
  # completar com o valor correto as linhas vazias das da variável day_effort
  mutate(
    day_effort2 = purrr::map(
      data, \(.x) rep(
        .x$day_effort[
          !is.na(
            .x$day_effort
          )
        ][1]
      )
    )
  ) |> 
  # desanihar os dados
  unnest(
    c(
      data, 
      day_effort2
    )
  ) |> 
  # desagrupar os dados
  ungroup() |> 
  # selecionar as colunas desejadas e excluir as indesejadas
  select(
    tidyselect::starts_with(c("uc", "ea")),
    season,
    year,
    sampling_day,
    day_effort = day_effort2,
    sp:number_observers,
    -day_effort,
    -tidyselect::starts_with("obs")
  ) |>
  # filtrar os dados pela UC e espécie desejadas
    dplyr::filter(
      uc_name == "Resex Tapajos-Arapiuns",
      sp == "Dasyprocta croconota"
    ) |> 
  relocate(
    uc_category,
    .before = uc_name
  ) |> 
  relocate(
    uc_name_abv,
    .after = uc_name
  )

# gerar tabela dinâmica dos dados completos
dados_filtrados |> 
  slice(
    1:1000
  ) |> 
  datatable(
    filter = list(
      position = "top"
    )
  )
```

O trecho do código que vai da linha 96 a 106 serve selecionar apenas as colunas de interesse presente nos dados originais. Note que os nomes das planilhas originais constam nesse trecho. Caso o nome de qualque uma dessas colunas seja alterado a função deixará de funcionar.

Outro aspecto importante é a presença de observações não preenchidas
(ex. células vazias) nos dados originais. A função foi desenha para
resolver alguns problemas presentes nos dados originais. Por exemplo,
nas o trecho do código das linhas 194 a 210 as observações vazias (`NA`s) são substituidas pelo valor correto na coluna `day_effort`. Essa correção continnuará sendo realizada em versões atualizadas dos dados do Monitora. Porém, se outras colunas além das que estão sendo corrigidas possuirem observações vazias os dados serão carregados e transformados, porém outras funções podem ter o seu funcionamento comprometido. Por exemplo, funções de visualização e do pacote `Distance` que podem não funcionar devido a ausência de observação.

Dentre todas as funções de carregamento de dados, apenas
`carregar_dados_brutos_xlsx()` carrega a base de dados originais do
Monitora, diretamente do diretório `data-raw/monitora_masto_aves_2023_04_04.xlsx`. Ao mesmo tempo que
carrega e transforma os dados, essa função gera uma versão em um formato mais leve, `.rds`, no diretório `data-raw` (`data-raw/monitora_masto_aves_2023_04_04.rds`). A função seguinte no
fluxo de trabalho carrega a base a partir dessa versão mais leve. Logo, sempre que houver atualizações no arquivo original de dados brutos é necessário iniciar a rotina de carregamento de dados necessariamente com a função `carregar_dados_brutos_xlsx()`.

# **PARTE II -- Carregando os dados para o R**

## **Dados brutos**

Não precisa se assustar com a infinidade de códigos no exemplo acima.
Eles foram utilizados apenas para ilustrar que construir essas funções facilita a execução e a reprodutibilidade das análise dos dados do Monitora. Para cada tarefa existe uma função cujo funcionamento necessita o preenchimento de alguns argumentos, ou mesmo de nenhum (embora seja sempre possível fornecê-los). Por
traz das cortinas, as funções executam as tarafas necessárias para se
obter o resultado desejado. Por exemplo, o mesmo resultado pode ser
obtido utilizando apenas duas funções: `carregar_dados_brutos_xlsx()`e
`gerar_tabdin_dados_brutos()`.

```{r}
# carregar dados brutos
dados_brutos <- carregar_dados_brutos_xlsx()

# gerar tabela dinamica dos dados brutos
gerar_tabdin_dados_brutos()
```

A função `gerar_tabdin_dados_brutos()`, por configuração, gera uma
tabela dinâmica com 1000 linhas. Você pode controlar o número de linhas pelo argumento `n_linhas =`. Mas atenção! Ela não funcionará com um número superior a **4.500 linhas**. Ao mudar a entrada de dados usando o argumento `dados =`, certifique-se de que seu número de linhas não exceda esse limite (ex. **4.500**). 

```{r}
gerar_tabdin_dados_brutos(
  n_linhas = 1:4500
)
```

## **Dados completos**

```{r}
# carregar dados para o R
dados_completos <- carregar_dados_completos() 

# gerar tabela dinamica dos dados completos
gerar_tabdin_dados_completos()
```

## **Dados filtrados**

```{r}
# carregar dados para o R
dados_filtrados <- carregar_dados_filtrados()

# gerar tabela dinâmica dos dados fitrados
gerar_tabdin_dados_filtrados()
```

# **Parte III -- Transformando dados para Distance**

## **Dados completos no formato Distance**

```{r}
# transformar os dados para o formato do Distance
dados_distanceR_completo <- transformar_para_distanceR_covariaveis()

# gerar tabela dinamica dos dados no formato do distance do R
gerar_tabdin_dados_selecionados_distanceR_cov()
```

# **PARTE IV -- Explorando e selecionando os dados para as análises**

Apresentamos abaixo um conjunto de ferramentas que permite diversas formas de explorar todo o conjunto de dados.

## **Selecionando os melhores espécies modelo de estudo de acordo com os dados**

Alguns cuidados devem ser tomados na preparação dos dados antes de serem analisados. O primeiro deles é o cuidado taxonômico. Para os dados do Monitora recomenda-se o uso dos dados das espécies validadas para análise pelo ICMBio, conforme o modelo utilizado para este fluxo de trabalho.

Alguns problemas com os dados, que podem trazer efeitos indesejados
sobre as análises, podem ser detectados durante a fase de exploração. Ao selecionar os dados que serão analisados, é importante observar os
seguintes aspectos:

**Suficência Amostral - número de ocorrências por espécie**

Para que o método de análise por distância possa ser utilizado para
estimativas baseadas em modelos, são recomendadas quantidades mínimas de registros de ocorrência e de transectos (Unidades Amostrais). Segundo BUCKLAND et. al. (2015), o número mínimo sugerido de animais ou grupos (ocorrências) é de 60 -- 80 animais (ou grupos) quando a amostragem é feita pelo método dos transectos lineares. É possível utilizar números menores que estes para realizar as análises, porém deve-se ter o cuidado de verificar se as funções de detecção estão bem modeladas.

Para dados que serão estratificados (divididos em subconjuntos), estes números recomendados se aplicam a cada subconjunto. Isso ocorre porque as funções de detecção serão modeladas para cada estrato
(p.ex.`Region.Label`), além da função de detecção para os dados globais. Um exemplo seria a análise dos dados, para uma mesma espécie, em diferentes UCs. Neste caso, o ideal seria ter a suficiência amostral mínima em cada UC para usar estratificação e estimar abundâncias e densidades em cada uma das UCs.

**Suficiência amostral - réplicas e repetições**

Para que haja uma boa cobertura da área de estudo e também uma boa
quantidade de amostras independentes para estimar as abundâncias e
densidades das espécies, é desejável um número satisfatório de réplicas independentes. Segundo BUCKLAND et al. (2015), o número mínimo de réplicas independentes para os transectos deve ser de 10-20, o que deve aumentar para espécies cujas populações são distribuídas em manchas.

De forma geral, para cada UC, o número de réplicas do Programa Monitora está abaixo do recomendado. O delinamento amostral atual para a compontente Florestal do subprograma Terrestre estabelece um número mínimo de três Estações Amostrais por Unidade de Conservação, o que é o caso de muitas UCs, chegando ao máximo de 9 estações amostrais por UC. O baixo número de réplicas espaciais idependentes não chega a ser um problema na estimativa de densidade da Área Coberta pela amostragem, mas limita uma boa estimativa de densidade total para a Unidade de Conservação.

Um outro aspecto relacionado a amostragem é o número de repetições por transecto. Segundo BUKLAND et al (2001, pg 79), as repetições devem ser incorporadas no esforço amostral multiplicando-se o número de vezes que o transecto foi percorrido pelo comprimento do transecto. A mesma recomendação é dada pelo Curso Online em Distance Sampling [link](https://workshops.distancesampling.org/online-course/lecturepdfs/Ch4/L4-3%20Sample%20Size.pdf). Esse ajuste no esforço amostral não deve ter grandes consequências para
um baixo número de repetições. Porém, números altos de amostragens repetidas e nã independentes levam a uma inflagem no tamanho da área coberta. Apenas para ilustar com um exemplo, para os dados da cutia *Dasyprocta croconota* da Resex Tapajós-Arapinuns, a Estação Amostral Boim foi percorrida durante 70 dias de amostragem. Isso significa que ajustando o comprimento do transecto de 5 km pelo número de repetições, o esforço amostral passou para 350 km. A área coberta aumentou em 70x, o que terá consequências sobre a estimativa densidade, que tenderá a ser subestimada. Além disso, o coeficiente de variação das estimativas de taxa de encontro, abundância e densidade também tenderão a aumentar pelo efeito da variações temporais entre as amostragens.

Uma forma de lidar com o excesso de amostragens repetidas é tratar as
repetições como efeitos aleatórios dos modelos. Isso requer o uso de
abordagens que vão além da amostragem por distância convecional, como o uso de Mixed Effect Models e Modelos Hierárquicos (p. ex. OEDEKOVEN et al. 2013, 2014). Essas abordagens ainda não foram implementadas em nosso fluxo de trabalho até a presente versão e pretendemos testar os códigos para esta abordagem utilizando o pacote unmarked até o final da vigência do presente projeto.

**Distribuição de frequência das ocorrências em relação à distância -
efeitos indesejados**

A distribuição ideal das frequências de ocorrência em relação à
distância deve apresentar as seguintes características: a frequência de ocorrência deve ser maior próximo a zero, apresentar um longo platô (ombro), e decair gradativamente com o aumento da distância. Isso significa que os animais são totalmente detectáveis na distância zero, seguem sendo bem detectáveis a distâncias curtas e vão perdendo
detectabilidade gradativamente com o aumento da distância.

Por isso, uma das etapas exploratórias é avaliar o histograma de
frequências de ocorrência ao longo da distância em relação ao transecto (opção abaixo). Algumas distribuições indicam problemas nos dados que podem dificultar o ajuste das funções de detecção. Tais como:

*Pico de ocorrências próximos à distância zero - spike near zero
distance*

Isso ocorre quando o número de observações próximos à distância zero é  inflado em relação às demais distâncias. O efeito gráfico será um pico no histograma em zero ou próximo a zero, conforme o exemplo abaixo para os dados extraídos das cutias (*Dasyprocta croconota*) na Resex Tapajós-Arapiuns.

![Distribuicao de Frequencia para *Dasyprocta croconota* na Resex
Tapajos-Arapiuns](`r here::here("output/Distribuicao_freq_Dasyprocta_ResexTapajos.png")`){width="75%"}

Este tipo de distribuição foi predominante para as espécies com o maior número de ocorrência nos dados de aves e mamíferos do Programa Monitora Florestal. Acreditamos que existem dois fatores que podem estar causando esse acúmulo de dados em zero ou próximo a ele. Um deles seria um viés para avistamento de animais na trilha em ambientes de floresta. As trilhas podem atrair animais, e também oferecem melhor visibilidade em relação à floresta, especialmente se o sub-bosque for denso. O outro fator seria um possível arredondamento nas distâncias próximas a zero, o que pode gerar um "amontoamento" nos dados (*heaping*). Recomenda-se que valores de distância perpendicular nunca sejam arredondados.

*Resposta evasiva das espécies em relação ao observador*

Para espécies que podem apresentar resposta de deslocamento em relação ao observador, um dos efeitos indesejados nos dados é o deslocamento das maiores frequências de observações para as distâncias perpendiculares intermediárias ao mesmo tempo que as frequências próximas ao observador são baixas. Uma alternativa, nesse caso, é constranger a função de deteção para monotonicidade, evitando que ela suba para se ajustar ao pico de frequência nas distâncias intermediárias.

*Viés de tamanho de grupo*

Um dos efeitos que pode ocorrer para espécies que formam grupos, é que grupos menores perdem a detectabilidade mais fácil do que grupos maiores com o aumento da distância. Esse viés pode ser testado na exploração dos dados das covariávies, plotando-se um gráfico de tamanho de grupo pela distância. Caso o viés ocorra, será uma observada uma tendência de registros somente de grupos maiores nas distâncias maiores. Nós adotamos a estratégia de tratar tamanho de grupo como covariável para espécies que formam grupos. Neste caso, ao mesmo tempo que lidamos com o efeito do tamanho do grupo na detectabilidade, incorporamos também o tamanho do grupo nas estimativas de densidade e abundância.

### **Exploração e seleção de dados**

#### **Aspectos relacionados ao número total de observações**

#### **Quantas observações foram validadas para quais níveis taxonômicos?**

Essas operações são realizadas sobre a tabela de dados `dados_completos` pois os dados que foram transformados para o formato do distace no R não possuem a coluna `validation`, necessária para essas opereações. Mais a frente o procedimento de como obter os dados selecionados e transformatos para o formato das análises será demonstrado.

```{r}
# contar observações validadas ao nível de espécie
n_obs_validadas <- contar_n_obs_validadas()
n_obs_validadas
```

Foram selecionadas apenas as observações validadas ao nível de espécie, somando um total `r n_obs_validadas[1]` observações.

```{r}
# gerar gráfico com número observações validadas para cada nível taxonômico
plotar_n_obs_validadas_interativo()
```

Finalmente chegamos ao subconjunto dos dados que será utilizado para
selecionar quais espécies serão analisadas.

```{r}
# gerar tabela de dados selecionados
dados_selecionados <- carregar_dados_selecionados()

# gerar tabdin dados_selecionados 
gerar_tabdin_dados_selecionados()
```

#### **Quantas unidades de conservação ao todo?**

```{r n_de_ucs}
# contar número total de UC's 
n_ucs <- contar_n_uc()
n_ucs
```

Os dados são provenientes de `r n_ucs` unidades de conservação ao todo.

#### **Quantas espécies ao todo?**

```{r}
n_sp <- contar_n_sp()
n_sp
```

Até aqui temos dados para `r n_sp` espécies.

#### **Quantas observações por unidade de conservação ao todo?**

```{r}
# contar número de observações por UC
n_obs_uc <- contar_n_obs_uc()

# gerar tabdin
gerar_tabdin_n_obs_uc()
```


```{r, fig.height=20, fig.align='center'}
# plotar o número de observações por UC
plotar_n_obs_uc_interativo()
```

#### **Quantas observações para cada espécie?**

```{r, fig.height=20}
# contar total sp
n_obs_sp <- contar_n_obs_sp()
n_obs_sp
```

```{r}
# gerar tabela dinâmica com o número total de obsevações por espécie
gerar_tabdin_n_obs_sp()
```

```{r, fig.height=20}
# plotar o o número de observações por UC
plotar_n_obs_sp_interativo()
```

Tabela interativa para consulta do número de observações por espécie.

```{r}
gerar_tabdin_n_obs_sp()
```

#### **Quais e quantas observações para cada espécie por unidades de conservação?**

```{r}
# gerar tabela com o número de observações por espécie e por UC
n_obs_sp_uc <- contar_n_obs_sp_uc()
n_obs_sp_uc
```


```{r}
gerar_tabdin_n_obs_sp_uc()
```

#### **Quantas unidades de conservação foram amostradas em cada ano?**

```{r, echo=FALSE}
# gerar tabela com o número de unidades de conservação amostradas em cada ano
n_ucs_ano <- contar_n_uc_ano()
n_ucs_ano
```

Gerar função para tabela dinâmica.

```{r}
gerar_tabdin_n_uc_ano()
```

#### **Quais unidades de conservação foram amostradas em um maior número de anos?**

```{r}
n_ano_uc <- contar_n_ano_uc()
n_ano_uc  
```

```{r}
gerar_tabdin_n_ano_uc()
```

#### **Quantas observações foram realizadas por UC em cada ano?**

```{r}
n_obs_uc_ano <- contar_n_obs_uc_ano()
n_obs_uc_ano
```

Tabela interativa para consultar quantas observações foram realizadas
por ano em cada UC

```{r}
gerar_tabdin_n_obs_uc_ano()
```

#### **Quantas observações para cada espécies por ano?**

```{r}
n_obs_sp_ano <- contar_n_obs_sp_ano()
n_obs_sp_ano
```

Tabela interativa para consultar quantas observações foram realizadas
para cada espécie em cada ano

```{r}
gerar_tabdin_n_obs_sp_ano()
```

#### **Quantas observações para cada espécies por UC e por ano?**

```{r}
n_obs_sp_uc_ano <- contar_n_obs_sp_uc_ano()
n_obs_sp_uc_ano
```

Tabela interativa para consultar quantas observações foram realizadas
para cada espécie em cada ano

```{r}
gerar_tabdin_n_obs_sp_uc_ano()
```

#### **Quantas observações para cada espécies por UC, por estação e por ano?**

```{r}
n_obs_sp_uc_estacao_ano <- contar_n_obs_sp_uc_estacao_ano()
n_obs_sp_uc_estacao_ano
```

```{r}
gerar_tabdin_n_obs_sp_uc_estacao_ano()
```

#### **Avaliando número de réplicas (Estações Amostrais) por UC**

#### **Selecionando melhores modelos de estudo considerando estratificação espacial/temporal -- se há suficiência amostral (60-80 observações) por estrato**

-   Possíveis estratificações espaciais

- EAs/UCs

- UCs/Espécies

- Possíveis estratificações temporais

- Espécie/UC/Ano

#### **Avaliando distância de truncamento**

-   Gráficos de distribuição das frequências de ocorrência x distância perpendicular.

#### **Distribuição de distâncias**

```{r distribuicao_dsitancia, warning=FALSE}
# gerar o gráfico exploratório da distribuição de distâncias perpendiculares para a espécies Dasyrocta croconota na Resex Tapajós-Arapiuns
fig <- dados_filtrados |>
  # excluir NA's da variável distance
  tidyr::drop_na(distance) |> 
  plotar_distribuicao_distancia_interativo()

fig
```

#### **Avaliando covariáveis**

As covariáveis devem ser pensadas de acordo com o grupo taxonômico.
Espécies que formam grupos devem ter a covariável 'size'. As estratégias de estratificação podem ser substituídas por covariáveis
também (estratos espaciais/ ano). Como covariável temporal, pode se pensar em usar, além do ano, a estação do ano (season), o horário do dia (para animais que variam a atividade). O horário do dia pode ser convertido em tempo após nascer do sol (como no exemplo). Mas para isso é necessário criar essa variável no dataset. E não é trivial porque precisa saber o horário de nascer do sol em cada dia/local para calcular.

# **PARTE V -- Ajustando os modelos**

## Fluxo de análise dos dados:

A seguir, apresentamos o fluxo de análise dos dados que envolve a fase exploratória, truncamento, ajuste e avaliação de modelos e estimativas de abundância e densidade para as espécies que selecionamos como modelo. Usamos como critérios de seleção tanto o número de ocorrências por Unidade de Conservação quanto a distribuição das frequências de observação, nos casos em que isso foi possível. De forma geral, as espécies com número satisfatório de ocorrências (\>60), apresentaram pico de observações próximos a zero.

Nós usamos como modelo para este fluxo Dasyprocta croconota da Resex Tapajós-Arapiuns, pelo grande número de ocorrências para uma mesma UC. Nós implementamos duas estratégias para lidar com os efeitos indesejados nos dados: pico próximo a zero (*heaping near zero*) e número excessivo de repetições amostrais na mesma trilha. Para lidar com os picos, testamos o uso dos dados com distâncias exatas e distâncias agrupadas. Para lidar com as repetições, testamos a análise dos dados com todas as repetições e com o número de repetições reduzidas. Essas estratégias estão descritas em Fluxos 1-3. No primero fluxo, comentamos também as escolhas feitas e os resultados obtidos. Os demais fluxos são repetições deste primeiro fluxo, porém com mudança na estrutura dos dados.

Especies com maior numero de ocorrencias/UC possibilitam testar, posteriormente, estratificações nos dados, preservando um número de ocorrências satisfatório dentro dos estratos. Por isso começamos apresentando um fluxo completo de análise, incluindo Amostragem por Distância Convencional, Amostragem por Distância com Múltiplas Covariáveis e Amostragem por Distância com Estratificação nos dados com as espécies com maior número de ocorrência.

## Espécie Modelo - Dasyprocta croconota - Resex Tapajós Arapiuns

![Fonte: biolib.cz](https://www.biolib.cz/IMG/GAL/BIG/205849.jpg)

Essa é a espécie com o mair número de ocorrências para uma mesma UC. Apresentou, como a maioria das espécies em diferentes UCs, um pico de ocorrências próximo a zero.

### Carregar Dados

Para selecionar do conjunto de dados da espécie e a Unidade de conservação de interesse, usar a função `transforma_para_distanceR_com_repeticao_filtra_uc_sp()`, especificando o nome da Unidade de conservação através do argumento `nome_uc` e o nome da espécie através do argumento `nome_sp`.

```{r}
# carregar dados
cutia_tap_arap <- transforma_para_distanceR_com_repeticao_filtra_uc_sp(
  nome_uc = "Resex Tapajos-Arapiuns",
  nome_sp = "Dasyprocta croconota"
) 

cutia_tap_arap
```

### Amostragem por Distância Convencional

#### Fluxo 1 - Distâncias exatas com todas as repetições

##### Plotando o histograma das frequências de ocorrência pela distância

O histograma interativo está disponível no app em Shiny `app_distancia_interativo.R`. A distribuição dos dados no histograma permite observar um pico de observações próximo a zero, além de uma considerável perda em detectabilidade a partir dos 20m. Vamos testar diferentes proporções de truncamento. É possível alterar a binagem dos histogramas através do argumento `largura_caixa`. Neste exemplo ajustamos para 1, o que facilita a observação de picos de detecação e efeitos de *heaping* nos dados.

```{r, fig.height=15, fig.width=10, warning=FALSE}
cutia_tap_arap |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 1)
```

##### Testando distância de truncamento (*w*)

Vamos explorar diferentes distâncias de truncamento para um mesmo modelo de distribuição half-normal. Optamos por truncar os dados pela percentagem para padronizar a rotina para diferentes espécies. Buckland et al. (2001) sugere um corte entre 5-10% das observações detectadas nas maiores distãncias. Vamos selecionar o valor de corte pelo modelo com melhor ajuste. Para os dados, testamos as seguintes proporções de corte de dados: 5, 10, 15, 20 e 25% das observações mais distantes. Geramos uma tabela comparando os modelos e também plotamos os gráficos dos modelos ajustados para os dados truncados.

###### Tabela com resumo comparativo dos modelos

```{r}
# conduz a selecao da melhor distancia de truncamento a partir do ajsute de modelos com funcao de deteccao half-normal sem termos de ajuste
cutia_tap_arap_dist_trunc <- cutia_tap_arap |> 
  selecionar_distancia_truncamento()

cutia_tap_arap_dist_trunc$selecao
```

###### Plotando o histograma com os dados truncados.

Histogramas resultantes dos modelos, com todas as distâncias de truncagem, para auxiliar na seleção da melhor distãncia.

```{r}
plotar_funcao_deteccao_selecao_distancia_truncamento(cutia_tap_arap_dist_trunc)
```

Após avaliar tanto o ajuste dos modelos quanto os gráficos, optamos por truncar 15% das observações feitas nas maiores distâncias. Apesar dos melhores valores de AIC e de ajuste do Cramér-von Mises para 25%, os histogramas com modelos ajustados para 25%, 20% e 15% apresentaram modelos quase lineares e com uma grande probabilidade de deteção nos últimos intervalos de distância. O modelo com corte de 10% apresentou uma curva decrescente e não tendeu a zero nas últimas distâncias. Já no modelos para 5% as funções de deteção tendem a zero nos últimos intervalos de distância. O corte de 10% das observações mais distantes resultou em uma distância de truncamento de 15m.

##### Ajustando diferentes modelos de funções de deteção

As funções de deteção são ajustadas através da função `ds()` no pacote Distence para o R. Para otimizar o fluxo de ajuste de funções, empacotamos as diferentes combinações de funções chave e termos de ajustes em três funções. São elas: `ajuste_modelos_distance_unif()`, para distribuição uniforme sem termos de ajuste e com termos de ajuste do tipo cosseno e polinomial simples, `ajuste_modelos_distance_hn()` para distribuição half-normal sem termos de ajuste e com termos de ajuste do tipo cosseno e polinomial de hermite; e `ajuste_modelos_distance_hr()` para distribuição hazard-rate sem termos de ajuste e com termos de ajuste do tipo cosseno e polinomial simples. Para definir a distância de truncamento dos dados é necessário fornecer o argumento `truncamento`, que pode ser definido tanto em percentagem de corte dos dados quanto em valor de distãncia.

###### Uniforme com termos de ajuste Cosseno e polinomial simples

```{r}
# ajustando a função de detecção uniforme para um truncamento de 10% dos dados
cutia_tap_arap_unif <- cutia_tap_arap |> 
  ajuste_modelos_distance_unif(truncamento = "10%")

```

Dentre as combinações de termos de ajustes para a função chave de distribuição uniforme, o Distance selecionou o modelo uniforme com ajuste polinomial simples, com as ordens 2, 4 e 6. Ele mantém esse modelo, e descarta os demais. Os *Warnings* indicando que a função de detecção não é estritamente monotônica avisam que os dados não foram constrangidos para a monotonicidade. Isso porque o uso de termos de ajustes, especialmente de ordens acima de 2, podem levar à perda da monotonidade (a curva pode se tornar crescente em algum momento, o que não é desejado). É preciso avaliar se a fala desse constragimento levou efetivamente à perda da monotonicidade ao olhar os gráficos de ajuste dos modelos.

###### Half-Normal sem termos de ajuste e com termos de ajuste Cosseno e Polinomial de Hermite

```{r}
# ajustando a função de detecção half-normal para um truncamento de 10% dos dados
cutia_tap_arap_hn <- cutia_tap_arap |> 
  ajuste_modelos_distance_hn(truncamento = "10%")
```

Neste caso, o modelo selecionado pelo Distance foi o Half-normal sem nenhum termo de ajuste.

###### Hazard-rate sem termos de ajuste e com termos de ajuste Cosseno e Polinomial de Hermite

```{r}
# ajustando a função de detecção hazard-rate para um truncamento de 10% dos dados
cutia_tap_arap_hr <- cutia_tap_arap |> 
  ajuste_modelos_distance_hr(truncamento = "10%")
```

Aqui o melhor modelo selecionado pelo Distance foi o Hazard-rate sem os termos de ajuste. Nesse caso, também há um *warning* para o problema na distribuição dos dados, que apresentam um pico próximo a distância zero e não são bem ajustados pelo hazard-hate.

##### Comparando os modelos

Para comparar os modelos é preciso avaliar três critérios: AIC, ajuste e forma das funções nos gráficos e bondade de ajuste. O pacote distance possui a função `summarize_ds_models`que gera uma tabela com os modelos para comparação de alguns parâmetros: a primeira coluna **Model**, indica as funções chaves e respectivos termos de ajuste; a coluna **Formula** apresenta as covariáveis, quando incluídas no modelo, ou \~1, quando não há covariáveis; **C-vM p-value** vai apresentar os valores de p para o teste de bondade de ajuste de Cramér-von Mises; $\hat{P_a}$ apresenta a probalidade de deteção global estimada para cada modelo; **se(**$\hat{P_a}$) apresenta o erro padrão para as estimativas de probabilidade de detecção; e $\Delta$AIC apresenta os valores de delta AIC.

###### Tabela com o resumo comparativo dos modelos

```{r}
fluxo1_lista_modelos_ajustados <- list(
  `half-normal` = cutia_tap_arap_hn, 
  `hazard-rate` = cutia_tap_arap_hr, 
  `uniforme` = cutia_tap_arap_unif
)

fluxo1_selecao_funcao_deteccao_termo_ajuste <- selecionar_funcao_deteccao_termo_ajuste(fluxo1_lista_modelos_ajustados)

fluxo1_selecao_funcao_deteccao_termo_ajuste
```

Dentre os modelos testados, o que apresentou melhor valor de ajuste e AIC foi o hazard-rate. O ajuste do Cramér-von Mises foi consideravelmente maior que os demais (para esse tipo de teste, quanto maior o valor de p, melhor o ajuste), assim como as diferenças no delta AIC foram bastante elevadas.

###### Gráficos de ajuste das funções de deteção às probabilidades de deteção

```{r}
# gerar uma lista com os modelos selecionados ordenados do melhor para o pior modelo
fluxo1_modelos_selecionados <- list(
  cutia_tap_arap_hr$`Sem termo`,
  cutia_tap_arap_unif$`Cosseno`,
  cutia_tap_arap_hn$`Cosseno`,
  cutia_tap_arap_unif$`Polinomial simples`,
  cutia_tap_arap_hn$`Sem termo`
)

# atribuir o nome dos modelos aos itens da lista

names(fluxo1_modelos_selecionados) <- fluxo1_selecao_funcao_deteccao_termo_ajuste$Model

# plotar a probabilidade de detecção observada (barras) e a esperada (linhas e pontos)
plotar_funcao_deteccao_modelos_selecionados(fluxo1_modelos_selecionados)
```

Olhando para os histogramas com modelos ajustados, é possível observar o efeito do acúmulo de observações próximo a zero. O modelo com a função chave hazard-hate sem termos de ajuste, apesar de ter apresentado o melhor valor de ajuste pelo Cramér-von Mises e o melhor valor de AIC, apresentou dois problemas. As probalidades de deteção estimadas por intevalo de distância (barras cinzas), ficaram muito baixas. Além disso, a curva da função de deteção apresenta pico na distância próxima a zero, decaindo rapidamente e se aproximando de zero ao longo do eixo das distãncias. Todos os outros quatro modelos tiveram ajuste e AIC bastante inferiores ao hazard-hate. Entretanto as curvas estão relativamente melhores. As curvas do segundo e terceiro modelo, uniforme com ajuste cosseno e half-normal com ajuste cosseno, respectivamente, tendem à perda de monotonicidade. As duas últimas curvas, para os modelos uniforme com ajuste polinomial simples e half-normal sem ajuste, não perdem a monotonicidade. De forma geral, as probabilidades de detecção não têm um bom ajuste abaixo da curva, e não apresentam um decaimento gradual com a distância. Esses são problemas inerentes à distribuição dos dados.

###### Teste de bondade de ajuste dos modelos e Q-Q plots

```{r}
bondade_ajuste_fluxo1 <- testar_bondade_ajuste(fluxo1_modelos_selecionados, plot = TRUE)
bondade_ajuste_fluxo1
```

Aqui são gerados Q-Q plots que permitem avaliar a qualidade do ajuste dos modelos. E também uma tabela com os resultados do Carmér-von Mises, onde W é o valor do teste e p seu valor de significância. Nesse caso, quanto maior o valor de p, melhor o ajuste do modelo.

##### Avaliando as estimativas de Abundância e Densidade

Aqui, são resumidos os dados de taxa de encontro, abundância e densidade em três tabelas.

###### Características da área de estudo e da taxa de encontro

```{r}
# gera lista contendo os modelos selecionados para cada função de detecção e termo de ajuste
fluxo1_lista_modelos_ajustados_termos <- list(
  cutia_tap_arap_hr$`Sem termo`,
  cutia_tap_arap_hn$Cosseno,
  cutia_tap_arap_unif$Cosseno,
  cutia_tap_arap_unif$`Polinomial simples`,
  cutia_tap_arap_hn$`Sem termo`
)

# área de estudo, tamanho da área de estudo, area coberta pelo esforço amostral, esforço amostral em metros, número de detecções, número de transectos (ea), taxa de encontro, coeficiente de variação da taxa de encontro  
fluxo1_caracteristicas_area_estudo_taxa_encontro <- fluxo1_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_area_estudo_taxa_encontro(resultado_selecao_modelos = fluxo1_selecao_funcao_deteccao_termo_ajuste)

fluxo1_caracteristicas_area_estudo_taxa_encontro
```

###### Características de abundância, esforço e detecção

```{r}
# área de estudo, tamanho da área de estudo, trilhas ou estações amostrais, esforço total em cada trilha, abundância estimada em cada estação amostral, número de detecções em cada estação amostral, área total amostrada
fluxo1_caracteristicas_esforco_abundancia_deteccao <- fluxo1_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_esforco_abundancia_deteccao(resultado_selecao_modelos = fluxo1_selecao_funcao_deteccao_termo_ajuste)

fluxo1_caracteristicas_esforco_abundancia_deteccao
```

###### Características de densidade

```{r}
# total, densidade estimada, erro padrão da densidade destimada, coeficiente de variação da densidade destimada, intervalo de confiança inferior e superior do coeficiente de variação, gruas de liberdade
fluxo1_caracteristicas_densidade <- fluxo1_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_densidade(resultado_selecao_modelos = fluxo1_selecao_funcao_deteccao_termo_ajuste)

fluxo1_caracteristicas_densidade
```

#### Fluxo 2 - Distâncias exatas com repetições reduzidas

##### Filtrando os dados para reduzir as repetições

```{r}
dados_selecionados <- carregar_dados_selecionados()
cutia_tap_arap_quase_sem_repeticao <- transforma_para_dsitanceR_quase_sem_repeticao_filtra_uc_sp_covariavel(
  dados = dados_selecionados,
  nome_uc = "Resex Tapajos-Arapiuns",
  nome_sp = "Dasyprocta croconota"
)

cutia_tap_arap_quase_sem_repeticao
```

##### Plotando o histograma das frequências de ocorrência pela distância

```{r, fig.height=15, fig.width=10}
cutia_tap_arap_quase_sem_repeticao |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 1)
```

##### Testando distância de truncamento (*w*)

###### Tabela com resumo comparativo dos modelos

```{r}
# conduz a selecao da melhor distancia de truncamento a partir do ajsute de modelos com funcao de deteccao half-normal sem termos de ajuste
cutia_tap_arap_quase_sem_repeticao_dist_trunc <- cutia_tap_arap_quase_sem_repeticao |> 
  selecionar_distancia_truncamento()

cutia_tap_arap_quase_sem_repeticao_dist_trunc$selecao
```

###### Plotando o histograma com os dados truncados.

```{r}
plotar_funcao_deteccao_selecao_distancia_truncamento(cutia_tap_arap_quase_sem_repeticao_dist_trunc)

```

##### Ajustando diferentes modelos de funções de deteção

###### Uniforme + Cosseno

```{r}
# ajustando a função de detecção uniforme para um truncamento de 10% dos dados
cutia_tap_arap_quase_sem_repeticao_unif <- cutia_tap_arap_quase_sem_repeticao |> 
  ajuste_modelos_distance_unif(truncamento = "10%")

```

###### Half-Normal sem termos de ajuste e com termos de ajuste

```{r}
# ajustando a função de detecção half-normal para um truncamento de 10% dos dados
cutia_tap_arap_quase_sem_repeticao_hn <- cutia_tap_arap_quase_sem_repeticao |> 
  ajuste_modelos_distance_hn(truncamento = "10%")
```

###### Hazard-rate sem termos de ajuste e com termos de ajuste

```{r}
# ajustando a função de detecção half-normal para um truncamento de 10% dos dados
cutia_tap_arap_quase_sem_repeticao_hr <- cutia_tap_arap_quase_sem_repeticao |> 
  ajuste_modelos_distance_hr(truncamento = "10%")
```

##### Comparando os modelos

###### Tabela com o resumo comparativo dos modelos

```{r}
fluxo2_lista_modelos_ajustados <- list(
  `half-normal` = cutia_tap_arap_quase_sem_repeticao_hn, 
  `hazard-rate` = cutia_tap_arap_quase_sem_repeticao_hr, 
  `uniforme` = cutia_tap_arap_quase_sem_repeticao_unif
)

fluxo2_selecao_funcao_deteccao_termo_ajuste <- selecionar_funcao_deteccao_termo_ajuste(fluxo2_lista_modelos_ajustados)

fluxo2_selecao_funcao_deteccao_termo_ajuste
```
###### Gráficos de ajuste das funções de deteção às probabilidades de deteção

```{r}
# gerar uma lista com os modelos selecionados ordenados do melhor para o pior modelo
fluxo2_modelos_selecionados <- list(
  cutia_tap_arap_quase_sem_repeticao_hr$`Sem termo`,
  cutia_tap_arap_quase_sem_repeticao_hn$`Cosseno`,
  cutia_tap_arap_quase_sem_repeticao_unif$`Cosseno`,
  cutia_tap_arap_quase_sem_repeticao_unif$`Polinomial simples`,
  cutia_tap_arap_quase_sem_repeticao_hn$`Sem termo`
)

# atribuir o nome dos modelos aos itens da lista

names(fluxo2_modelos_selecionados) <- fluxo2_selecao_funcao_deteccao_termo_ajuste$Model

# plotar a probabilidade de detecção observada (barras) e a esperada (linhas e pontos)
plotar_funcao_deteccao_modelos_selecionados(fluxo2_modelos_selecionados)
```

###### Teste de bondade de ajuste dos modelos e Q-Q plots

```{r}
bondade_ajuste_fluxo2 <- testar_bondade_ajuste(fluxo2_modelos_selecionados, plot = TRUE)
bondade_ajuste_fluxo2
```

##### Avaliando as estimativas de Abundância e Densidade

###### Características da área de estudo e da taxa de encontro

```{r}
# gera lista contendo os modelos selecionados para cada função de detecção e termo de ajuste
fluxo2_lista_modelos_ajustados_termos <- list(
  cutia_tap_arap_quase_sem_repeticao_hr$`Sem termo`,
  cutia_tap_arap_quase_sem_repeticao_hn$`Cosseno`,
  cutia_tap_arap_quase_sem_repeticao_unif$`Cosseno`,
  cutia_tap_arap_quase_sem_repeticao_unif$`Polinomial simples`,
  cutia_tap_arap_quase_sem_repeticao_hn$`Sem termo`
)

# área de estudo, tamanho da área de estudo, area coberta pelo esforço amostral, esforço amostral em metros, número de detecções, número de transectos (ea), taxa de encontro, coeficiente de variação da taxa de encontro  
fluxo2_caracteristicas_area_estudo_taxa_encontro <- fluxo2_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_area_estudo_taxa_encontro(resultado_selecao_modelos = fluxo2_selecao_funcao_deteccao_termo_ajuste)

fluxo2_caracteristicas_area_estudo_taxa_encontro
```

###### Características de abundância, esforço e detecção


```{r}
# área de estudo, tamanho da área de estudo, trilhas ou estações amostrais, esforço total em cada trilha, abundância estimada em cada estação amostral, número de detecções em cada estação amostral, área total amostrada
fluxo2_caracteristicas_esforco_abundancia_deteccao <- fluxo2_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_esforco_abundancia_deteccao(resultado_selecao_modelos = fluxo2_selecao_funcao_deteccao_termo_ajuste)

fluxo2_caracteristicas_esforco_abundancia_deteccao
```

###### Características de densidade

```{r}
# total, densidade estimada, erro padrão da densidade destimada, coeficiente de variação da densidade destimada, intervalo de confiança inferior e superior do coeficiente de variação, gruas de liberdade
fluxo2_caracteristicas_densidade <- fluxo2_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_densidade(resultado_selecao_modelos = fluxo2_selecao_funcao_deteccao_termo_ajuste)

fluxo2_caracteristicas_densidade
```

#### Fluxo 3 - Distâncias agrupadas com todas as repetições

Aqui vamos partir do mesmo conjunto de dados do Fluxo 1 (`cutia_tap_arap`), com todas as repetições, mas vamos agrupar as distâncias em intervalos. Vamos usar o mesmo valor de truncamento, removendo 10% das observações nas maiores distâncias, o que significa que aproveitaremos as observações feitas até 15m de distância do observador.

##### Plotando o histograma das frequências de ocorrência pela distância

O histograma interativo está disponível no app em Shiny `app_distancia_interativo.R`.

Aqui, plotamos quatro histogramas com binagens diferentes, para observar o efeito de agrupar os dados sobre as distribuições das frequências de ocorrência nos histogramas.

```{r, fig.height=15, fig.width=10}
cutia_tap_arap |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 1)

cutia_tap_arap |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 2)

cutia_tap_arap |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 3)

cutia_tap_arap |> 
  drop_na(distance) |> 
plotar_distribuicao_distancia_interativo(largura_caixa = 5)

```

##### Definindo os intevalos de distância de agrupamento

###### Primeira binagem - Intervalos iguais de 1.5m

```{r}
cutia_tap_arap_bin1 <- create_bins(
  cutia_tap_arap[!is.na(cutia_tap_arap$distance),], 
  c(0, 1.5, 3, 4.5, 6, 7.5, 9, 10.5, 12, 13.5, 15)
)
```

###### Segunda binagem - Primeiro intervalo de 1m e demais intervalos de 1.4m

```{r}
cutia_tap_arap_bin2 <- create_bins(
  cutia_tap_arap[!is.na(cutia_tap_arap$distance),], 
  c(0, 1, 2.4, 3.8, 5.2, 6.6, 8, 9.4, 10.8, 12.2, 13.6, 15)
)
```

###### Terceira binagem - Intervalos iguais de 2.5m

```{r}
cutia_tap_arap_bin3 <- create_bins(
  cutia_tap_arap[!is.na(cutia_tap_arap$distance),], 
  c(0, 2.5, 5, 7.5, 10, 12.5, 15)
)
```

##### Ajustando diferentes modelos de funções de deteção

###### Uniforme + Cosseno

Primeira Binagem

```{r}

cutia_tap_arap_bin1_unif <- cutia_tap_arap_bin1 |> 
  ajuste_modelos_distance_unif(truncamento = 15)

```

Segunda binagem

```{r}

cutia_tap_arap_bin2_unif <- cutia_tap_arap_bin2 |> 
  ajuste_modelos_distance_unif(truncamento = 15)

```

Terceira binagem

```{r}

cutia_tap_arap_bin3_unif <- cutia_tap_arap_bin3 |> 
  ajuste_modelos_distance_unif(truncamento = 15)

```

###### Half-Normal sem termos de ajuste e com termos de ajuste

Primeira binagem

```{r}

cutia_tap_arap_bin1_hn <- cutia_tap_arap_bin1 |> 
  ajuste_modelos_distance_hn(truncamento = 15)

```

Segunda binagem

```{r}

cutia_tap_arap_bin2_hn <- cutia_tap_arap_bin2 |> 
  ajuste_modelos_distance_hn(truncamento = 15)

```

Terceira binagem

```{r}

cutia_tap_arap_bin3_hn <- cutia_tap_arap_bin3 |> 
  ajuste_modelos_distance_hn(truncamento = 15)

```

###### Hazard-rate sem termos de ajuste e com termos de ajuste

Primeira binagem

```{r}

cutia_tap_arap_bin1_hr <- cutia_tap_arap_bin1 |> 
  ajuste_modelos_distance_hr(truncamento = 15)

```

Segunda binagem

```{r}

cutia_tap_arap_bin2_hr <- cutia_tap_arap_bin2 |> 
  ajuste_modelos_distance_hr(truncamento = 15)

```

Terceira binagem

```{r}

cutia_tap_arap_bin3_hr <- cutia_tap_arap_bin3 |> 
  ajuste_modelos_distance_hr(truncamento = 15)

```

##### Comparando os modelos

###### Tabela com o resumo comparativo dos modelos

```{r}
fluxo3.1_lista_modelos_ajustados <- list(
  `half-normal` = cutia_tap_arap_bin1_hn, 
  `hazard-rate` = cutia_tap_arap_bin1_hr, 
  `uniforme` = cutia_tap_arap_bin1_unif
)

fluxo3.1_selecao_funcao_deteccao_termo_ajuste <- selecionar_funcao_deteccao_termo_ajuste(fluxo3.1_lista_modelos_ajustados)

fluxo3.1_selecao_funcao_deteccao_termo_ajuste
```

```{r}
fluxo3.2_lista_modelos_ajustados <- list(
  `half-normal` = cutia_tap_arap_bin2_hn, 
  `hazard-rate` = cutia_tap_arap_bin2_hr, 
  `uniforme` = cutia_tap_arap_bin2_unif
)

fluxo3.2_selecao_funcao_deteccao_termo_ajuste <- selecionar_funcao_deteccao_termo_ajuste(fluxo3.2_lista_modelos_ajustados)

fluxo3.2_selecao_funcao_deteccao_termo_ajuste
```

```{r}
fluxo3.3_lista_modelos_ajustados <- list(
  `half-normal` = cutia_tap_arap_bin3_hn, 
  `hazard-rate` = cutia_tap_arap_bin3_hr, 
  `uniforme` = cutia_tap_arap_bin3_unif
)

fluxo3.3_selecao_funcao_deteccao_termo_ajuste <- selecionar_funcao_deteccao_termo_ajuste(fluxo3.3_lista_modelos_ajustados)

fluxo3.3_selecao_funcao_deteccao_termo_ajuste
```

###### Gráficos de ajuste das funções de deteção às probabilidades de deteção

Primeira binagem

```{r}
fluxo3.1_modelos_selecionados <- list(
  cutia_tap_arap_bin1_hn$`Cosseno`,
  cutia_tap_arap_bin1_unif$`Cosseno`,
  cutia_tap_arap_bin1_hr$`Sem termo`,
  cutia_tap_arap_bin1_unif$`Polinomial simples`,
  cutia_tap_arap_bin1_hn$`Sem termo`
)

plotar_funcao_deteccao_modelos_selecionados(fluxo3.1_modelos_selecionados)
```

Segunda binagem

```{r}
fluxo3.2_modelos_selecionados <- list(
  cutia_tap_arap_bin2_hn$`Cosseno`,
  cutia_tap_arap_bin2_hr$`Sem termo`,
  cutia_tap_arap_bin2_unif$`Cosseno`,
  cutia_tap_arap_bin2_unif$`Polinomial simples`,
  cutia_tap_arap_bin2_hn$`Sem termo`
)

plotar_funcao_deteccao_modelos_selecionados(fluxo3.2_modelos_selecionados)
```

Terceira binagem

```{r}
fluxo3.3_modelos_selecionados <- list(
  cutia_tap_arap_bin3_hn$`Cosseno`,
  cutia_tap_arap_bin3_hr$`Cosseno`,
  cutia_tap_arap_bin3_hr$`Polinomial simples`,
  cutia_tap_arap_bin3_hr$`Sem termo`,
  cutia_tap_arap_bin3_unif$`Cosseno`,
  cutia_tap_arap_bin3_unif$`Polinomial simples`,
  cutia_tap_arap_bin3_hn$`Sem termo`
)

plotar_funcao_deteccao_modelos_selecionados(fluxo3.3_modelos_selecionados)
```

###### Teste de bondade de ajuste dos modelos e Q-Q plots

Ainda estamos ajustando os outputs para os testes de bondade, pois a binagem um conflito com o formato de tabela definido pela função original.

Primeira binagem

```{r, results='hide'}
bondade_ajuste_fluxo3.1 <- testar_bondade_ajuste(fluxo3.1_modelos_selecionados, plot = TRUE, chisq = TRUE, breaks =  c(0, 1.5, 3, 4.5, 6, 7.5, 9, 10.5, 12, 13.5, 15))
bondade_ajuste_fluxo3.1
```

Segunda binagem

```{r, results='hide'}
bondade_ajuste_fluxo3.2 <- testar_bondade_ajuste(fluxo3.2_modelos_selecionados)
bondade_ajuste_fluxo3.2
```

Terceira binagem

```{r, results='hide'}
bondade_ajuste_fluxo3.3 <- testar_bondade_ajuste(fluxo3.3_modelos_selecionados)
bondade_ajuste_fluxo3.3
```


##### Avaliando as estimativas de Abundância e Densidade

###### Características da área de estudo e da taxa de encontro

Primeira binagem

```{r}
# gera lista contendo os modelos selecionados para cada função de detecção e termo de ajuste
fluxo3.1_lista_modelos_ajustados_termos <- list(
  cutia_tap_arap_bin1_hn$`Cosseno`,
  cutia_tap_arap_bin1_unif$`Cosseno`,
  cutia_tap_arap_bin1_hr$`Sem termo`,
  cutia_tap_arap_bin1_unif$`Polinomial simples`,
  cutia_tap_arap_bin1_hn$`Sem termo`
)

# área de estudo, tamanho da área de estudo, area coberta pelo esforço amostral, esforço amostral em metros, número de detecções, número de transectos (ea), taxa de encontro, coeficiente de variação da taxa de encontro  
fluxo3.1_caracteristicas_area_estudo_taxa_encontro <- fluxo3.1_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_area_estudo_taxa_encontro(resultado_selecao_modelos = fluxo3.1_selecao_funcao_deteccao_termo_ajuste)

fluxo3.1_caracteristicas_area_estudo_taxa_encontro
```

Segunda binagem

```{r}
# gera lista contendo os modelos selecionados para cada função de detecção e termo de ajuste
fluxo3.2_lista_modelos_ajustados_termos <- list(
  cutia_tap_arap_bin2_hn$`Cosseno`,
  cutia_tap_arap_bin2_hr$`Sem termo`,
  cutia_tap_arap_bin2_unif$`Cosseno`,
  cutia_tap_arap_bin2_unif$`Polinomial simples`,
  cutia_tap_arap_bin2_hn$`Sem termo`
)

# área de estudo, tamanho da área de estudo, area coberta pelo esforço amostral, esforço amostral em metros, número de detecções, número de transectos (ea), taxa de encontro, coeficiente de variação da taxa de encontro  
fluxo3.2_caracteristicas_area_estudo_taxa_encontro <- fluxo3.2_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_area_estudo_taxa_encontro(resultado_selecao_modelos = fluxo3.2_selecao_funcao_deteccao_termo_ajuste)

fluxo3.2_caracteristicas_area_estudo_taxa_encontro
```

Terceira binagem

```{r}
# gera lista contendo os modelos selecionados para cada função de detecção e termo de ajuste
fluxo3.3_lista_modelos_ajustados_termos <- list(
  cutia_tap_arap_bin3_hn$`Cosseno`,
  cutia_tap_arap_bin3_hr$`Cosseno`,
  cutia_tap_arap_bin3_hr$`Polinomial simples`,
  cutia_tap_arap_bin3_hr$`Sem termo`,
  cutia_tap_arap_bin3_unif$`Cosseno`,
  cutia_tap_arap_bin3_unif$`Polinomial simples`,
  cutia_tap_arap_bin3_hn$`Sem termo`
)

# área de estudo, tamanho da área de estudo, area coberta pelo esforço amostral, esforço amostral em metros, número de detecções, número de transectos (ea), taxa de encontro, coeficiente de variação da taxa de encontro  
fluxo3.3_caracteristicas_area_estudo_taxa_encontro <- fluxo3.3_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_area_estudo_taxa_encontro(resultado_selecao_modelos = fluxo3.3_selecao_funcao_deteccao_termo_ajuste)

fluxo3.3_caracteristicas_area_estudo_taxa_encontro
```



###### Características de abundância, esforço e detecção

Primeira binagem
```{r}
# área de estudo, tamanho da área de estudo, trilhas ou estações amostrais, esforço total em cada trilha, abundância estimada em cada estação amostral, número de detecções em cada estação amostral, área total amostrada
fluxo3.1_caracteristicas_esforco_abundancia_deteccao <- fluxo3.1_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_esforco_abundancia_deteccao(resultado_selecao_modelos = fluxo3.1_selecao_funcao_deteccao_termo_ajuste)

fluxo3.1_caracteristicas_esforco_abundancia_deteccao
```

Segunda binagem
```{r}
# área de estudo, tamanho da área de estudo, trilhas ou estações amostrais, esforço total em cada trilha, abundância estimada em cada estação amostral, número de detecções em cada estação amostral, área total amostrada
fluxo3.2_caracteristicas_esforco_abundancia_deteccao <- fluxo3.2_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_esforco_abundancia_deteccao(resultado_selecao_modelos = fluxo3.2_selecao_funcao_deteccao_termo_ajuste)

fluxo3.2_caracteristicas_esforco_abundancia_deteccao
```

Terceira binagem
```{r}
# área de estudo, tamanho da área de estudo, trilhas ou estações amostrais, esforço total em cada trilha, abundância estimada em cada estação amostral, número de detecções em cada estação amostral, área total amostrada
fluxo3.3_caracteristicas_esforco_abundancia_deteccao <- fluxo3.3_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_esforco_abundancia_deteccao(resultado_selecao_modelos = fluxo3.3_selecao_funcao_deteccao_termo_ajuste)

fluxo3.3_caracteristicas_esforco_abundancia_deteccao
```

###### Características de densidade

Primeira binagem

```{r}
# total, densidade estimada, erro padrão da densidade destimada, coeficiente de variação da densidade destimada, intervalo de confiança inferior e superior do coeficiente de variação, gruas de liberdade
fluxo3.1_caracteristicas_densidade <- fluxo3.1_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_densidade(resultado_selecao_modelos = fluxo3.1_selecao_funcao_deteccao_termo_ajuste)

fluxo3.1_caracteristicas_densidade
```

Segunda binagem

```{r}
# total, densidade estimada, erro padrão da densidade destimada, coeficiente de variação da densidade destimada, intervalo de confiança inferior e superior do coeficiente de variação, gruas de liberdade
fluxo3.2_caracteristicas_densidade <- fluxo3.2_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_densidade(resultado_selecao_modelos = fluxo3.2_selecao_funcao_deteccao_termo_ajuste)

fluxo3.2_caracteristicas_densidade
```

Terceira binagem

```{r}
# total, densidade estimada, erro padrão da densidade destimada, coeficiente de variação da densidade destimada, intervalo de confiança inferior e superior do coeficiente de variação, gruas de liberdade
fluxo3.3_caracteristicas_densidade <- fluxo3.3_lista_modelos_ajustados_termos |> 
  gerar_caracteristicas_densidade(resultado_selecao_modelos = fluxo3.3_selecao_funcao_deteccao_termo_ajuste)

fluxo3.3_caracteristicas_densidade
```

### Amostragem por Distância com Múltiplas Covariáveis

Aqui, vamos usar a abordagem do Fluxo 2, com amostragens reduzidas, para o ajuste de covariáveis. Vamos usar o tamanho do grupo como covariável.

##### Ajustando diferentes modelos com covariáveis

Para o uso de coveriáveis, podemos usar somente as distribuições half-normal ou hazard-rate, pois ambas possuem o parâmetro escalar pelo qual o vetor das covariáveis será multiplicado. Não é recomendável o uso de termos de ajuste com o uso de covariáveis pela grande chance de perda de monotonicidade nas curvas das funções de detecção. Assim, vamos trabalhar com as seguintes combinações de modelos

###### Half-normal sem termos de ajuste (HN)

```{r}
# ajustando a função de detecção half-normal para um truncamento de 10% dos dados
cutia_cov_hn <- cutia_tap_arap_quase_sem_repeticao |> 
  ajuste_modelos_distance_hn(lista_termos_ajuste = list(`Sem termo`= NULL),truncamento = "10%")
```


###### HN + Tamanho do grupo (HN + S)

```{r}
# ajustando a função de detecção half-normal para um truncamento de 10% dos dados
cutia_cov_hn_s <- cutia_tap_arap_quase_sem_repeticao |> 
  ajuste_modelos_distance_hn(lista_termos_ajuste = list(`Sem termo`= NULL),truncamento = "10%", formula = ~size)
```

###### Hazard-rate sem termos de ajuste (HZ)

```{r}
# ajustando a função de detecção half-normal para um truncamento de 10% dos dados
cutia_cov_hr <- cutia_tap_arap_quase_sem_repeticao |> 
  ajuste_modelos_distance_hr(lista_termos_ajuste = list(`Sem termo`= NULL),truncamento = "10%")
```

###### HZ + Tamanho do grupo (HZ + S)

```{r}
# ajustando a função de detecção half-normal para um truncamento de 10% dos dados
cutia_cov_hr_s <- cutia_tap_arap_quase_sem_repeticao |> 
  ajuste_modelos_distance_hr(lista_termos_ajuste = list(`Sem termo`= NULL),truncamento = "10%", formula = ~size)
```

##### Comparando os modelos

###### Tabela com o resumo comparativo dos modelos

Ainda estamos ajustando a função para poder gerar a tabela com o resumo dos resultados. A função criada para gerar tabela ainda não comporta os dados de modelos com covariáveis.

```{r, results='hide'}
cov_lista_modelos_ajustados <- list(
  `half-normal` = cutia_cov_hn, 
  `hazard-rate` = cutia_cov_hr
)

cov_selecao_funcao_deteccao_termo_ajuste <- selecionar_funcao_deteccao_termo_ajuste(cov_lista_modelos_ajustados)
```

###### Gráficos de ajuste das funções de deteção às probabilidades de deteção

Ainda estamos ajustando a função para poder gerar os gráficos dos modelos com covariáveis. A função criada para os gráficos ainda não comporta os dados de modelos com covariáveis.

```{r}
cov_modelos_selecionados <- list(
  cutia_cov_hn$`Sem termo`,
  cutia_cov_hr$`Sem termo`
)

plotar_funcao_deteccao_modelos_selecionados(cov_modelos_selecionados)
```

###### Teste de bondade de ajuste dos modelos e Q-Q plots

Ainda estamos ajustando a função para poder gerar a tabela com os resultados do Cramér-von Mises e os gráficos dos modelos com covariáveis. A função criada para gerar tabela e os Q-Q plots ainda não comporta os dados de modelos com covariáveis.

```{r}
bondade_ajuste_cov <- testar_bondade_ajuste(cov_modelos_selecionados, plot = TRUE)
bondade_ajuste_cov
```

##### Avaliando as estimativas de Abundância e Densidade

Para o uso de covariáveis, as estimativas de abundância/densidade devem ser feitas através do bootstrap (função `bootdht` do Distance). Ainda estamos implementando o bootstrap em nosso fluxo de estimativas de taxa de encontro, abundância e densidade.
